{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import skimage.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dir = \"/home/himangi/8th-Sem/major-project/Scene-Graph-Generation/\"\n",
    "dir_img = \"/media/himangi/Seagate Backup Plus Drive/major_project/VRD/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bb_batch():\n",
    "\twith open(_dir + \"vrd-dataset/train.pkl\", 'rb') as infile:\n",
    "\t\tdata = pkl.load(infile)\n",
    "\t\n",
    "\td = dict()\n",
    "\n",
    "\tfor img_data in data[0:100]:\n",
    "# \t\tprint (img_data)\n",
    "\t\tif img_data != None:\n",
    "\t\t\tx = []\n",
    "\t\t\ty = []\n",
    "\t\t\timg_name = img_data['img_path'][8:]\n",
    "\t\t\td[img_name] = []\n",
    "\t\t\tfor i, j, k in zip(img_data['ix1'], img_data['ix2'], img_data['rel_classes']):\n",
    "\t\t\t\tl = []\n",
    "\t\t\t\tl.append([bb for bb in img_data['boxes'][i]])\n",
    "\t\t\t\tl.append([bb for bb in img_data['boxes'][j]])\n",
    "\t\t\t\tx.append(l)\n",
    "\t\t\t\ty.append(k[0])\n",
    "\n",
    "\t\t\td[img_name].append(x)\n",
    "\t\t\td[img_name].append(y)\n",
    "\n",
    "\treturn d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_bb_batch(key, val):\n",
    "\n",
    "    # Image in bounding box of x bb\n",
    "    y = []\n",
    "    tensor_list = []\n",
    "    img = sio.imread(dir_img + str(key))\n",
    "    print (key, len(val[0]))\n",
    "    for v in val[0]:   \n",
    "        sub = img[v[0][1]:v[0][1]+v[0][3], v[0][0]:v[0][0]+v[0][2]]\n",
    "        obj = img[v[1][1]:v[1][1]+v[1][3], v[1][0]:v[1][0]+v[1][2]]\n",
    "        sub_resized = cv2.resize(sub, (128, 128))\n",
    "        obj_resized = cv2.resize(obj, (128, 128))\n",
    "\n",
    "        sub_resized = np.asarray(sub_resized).transpose(-1, 0, 1) \n",
    "        sub_resized = torch.from_numpy(np.asarray(sub_resized)) \n",
    "\n",
    "        obj_resized = np.asarray(obj_resized).transpose(-1, 0, 1) \n",
    "        obj_resized = torch.from_numpy(np.asarray(obj_resized)) \n",
    "\n",
    "        rel = torch.cat((sub_resized, obj_resized), 0)\n",
    "        tensor_list.append(rel)\n",
    "        print (rel.shape)    \n",
    "    \n",
    "    # One-hot vector of val[1]\n",
    "    for label in val[1]:\n",
    "        y.append(label)\n",
    "\n",
    "#     print (y)\n",
    "    return (tensor_list, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sg_dataset/sg_train_images/908984325_df6244e5b7_b.jpg', 21)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/187448937_fdb1809fe3_b.jpg', 6)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/7960131502_3160a7f683_b.jpg', 4)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/8202503478_e2a837a373_b.jpg', 12)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/7562763590_e45aec394f_b.jpg', 8)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/1348163097_6d49676ae8_o.jpg', 10)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/2797293301_713a9a64ab_o.jpg', 12)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/6179115649_b110ff816c_b.jpg', 7)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/7568880522_18abd0af4f_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/3385172794_f1a5d0903c_b.jpg', 8)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5628092207_ac97d56001_b.jpg', 7)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/2560497338_093fc2663c_b.jpg', 10)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5127932909_d970f00dab_b.jpg', 6)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/8675597038_066bc8393c_b.jpg', 10)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/8356744181_09b9b2e879_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/3508178635_ea0291ec9a_b.jpg', 14)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5110722337_31349f9058_b.jpg', 7)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/2226297726_92f46e3aa8_b.jpg', 6)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/210903242_42780ed8fd_o.jpg', 3)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/339163822_22558dd207_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/94288580_29b1cedd2f_b.jpg', 10)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/6904037743_16170bcc6d_b.jpg', 11)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/7268635618_b4801110ca_b.jpg', 16)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5828910434_4f910e24cf_b.jpg', 1)\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/2080830859_642e373002_b.jpg', 13)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/308042862_37894a5225_b.jpg', 10)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5161016911_c84801d340_b.jpg', 12)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/1681852402_c832132ae6_o.jpg', 13)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/6544302317_e93722592f_b.jpg', 3)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sg_dataset/sg_train_images/6278963407_40ac1ed7e5_b.jpg', 1)\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/10007531244_0f2c46cf70_b.jpg', 1)\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/49523582_461040cc4e_o.jpg', 2)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/167210044_ddc9890c57_b.jpg', 6)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/9553510705_ee9155a2dd_b.jpg', 1)\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/1122205547_ac274ee77e_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5526173107_447a4419bf_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/4527308553_57e0e0348f_b.jpg', 4)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/6147407740_4291dd4aed_b.jpg', 3)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5015851966_4042f5ce85_b.jpg', 2)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/4342804425_5cfd6e7c67_b.jpg', 8)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/3008054318_8dfe57c0d0_b.jpg', 16)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5451022449_f832152616_b.jpg', 11)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/6684668915_6301c466d5_b.jpg', 14)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/7748672286_1e9e3a8bdb_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/559863781_43f5f21370_o.jpg', 4)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/215142759_6b7e7a6c23_b.jpg', 2)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/2946311692_f8426bf3fb_b.jpg', 12)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5415160205_15e9e4f4c6_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/3910287866_5c70e3d272_b.jpg', 9)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/3707816695_9a29f39fc6_b.jpg', 13)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/1307293943_01237bc64c_b.jpg', 13)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/2582945257_1ae179fa87_b.jpg', 7)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/508537639_845774e06a_b.jpg', 9)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/4664804932_fe40fa2372_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/8092563266_1d6e7f65ca_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/9414483501_ff59654a0f_b.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/9777495065_95f8e495ca_b.jpg', 4)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/5004931994_9906d0cd2b_b.jpg', 3)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/128413566_79824e8a4e_o.jpg', 14)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/9010812893_72d5e7187c_b.jpg', 6)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/4851905621_bea86f5454_b.jpg', 7)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/105683387_7886145a3f_o.jpg', 5)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "('sg_dataset/sg_train_images/8665247006_b220138080_b.jpg', 6)\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n",
      "torch.Size([6, 128, 128])\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/media/himangi/Seagate Backup Plus Drive/major_project/VRD/sg_dataset/sg_train_images/10213385425_458e29cda0_b.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-1f3e31b04da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcheck_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md_bb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mt_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_image_bb_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mcheck_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcheck_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-a0a2e77c16d2>\u001b[0m in \u001b[0;36mcreate_image_bb_batch\u001b[0;34m(key, val)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtensor_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_img\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/himangi/jupyterenv/local/lib/python2.7/site-packages/skimage/io/_io.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/himangi/jupyterenv/local/lib/python2.7/site-packages/skimage/io/manage_plugins.pyc\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                (plugin, kind))\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/himangi/jupyterenv/local/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/media/himangi/Seagate Backup Plus Drive/major_project/VRD/sg_dataset/sg_train_images/10213385425_458e29cda0_b.jpg'"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    d_bb = create_bb_batch()\n",
    "    final_tensor_list = []\n",
    "    y = []\n",
    "    check_x = []\n",
    "    check_y = []\n",
    "    for key, val in d_bb.items():\n",
    "        t_l, label = create_image_bb_batch(key, val)\n",
    "        check_x.append(len(t_l))\n",
    "        check_y.append(len(label))\n",
    "        for i in t_l:\n",
    "            final_tensor_list.append(i)\n",
    "        for j in label:\n",
    "            y.append(j)\n",
    "        \n",
    "    x = torch.stack(final_tensor_list)\n",
    "    y = torch.Tensor(y)\n",
    "    x_ = x\n",
    "    y_ = y\n",
    "    print (x.shape, y.shape)\n",
    "    \n",
    "    print (sum(check_x), sum(check_y))\n",
    "    \n",
    "    torch.save(x, str(_dir) + 'data/visual_sub_obj_train_x_100.pt')\n",
    "    torch.save(y, str(_dir) + 'data/visual_sub_obj_train_y_100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([692, 6, 128, 128]), torch.Size([692]))\n"
     ]
    }
   ],
   "source": [
    "torch.save(x_, str(_dir) + 'data/heatmap_sub_obj_train_x_100.pt')\n",
    "torch.save(y_, str(_dir) + 'data/heatmap_sub_obj_train_y_100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
